# log-pipeline
ì§ë°© ì•± ë¡œê·¸ ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„/ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• 

# ğŸ  ì§ë°© ë¡œê·¸ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• í”„ë¡œì íŠ¸

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![Apache Kafka](https://img.shields.io/badge/Apache-Kafka-231F20.svg?logo=apachekafka)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Apache-Spark-E25A1C.svg?logo=apachespark)](https://spark.apache.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-569A31.svg?logo=amazons3)](https://aws.amazon.com/s3/)
[![Git](https://img.shields.io/badge/Git-Collaboration-F05032.svg?logo=git)](https://git-scm.com/)

> ì§ë°© ì•±ì˜ ë¡œê·¸ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬, ë°ì´í„°ì˜ ìˆ˜ì§‘ë¶€í„° ì²˜ë¦¬, ì ì¬, ì‹œê°í™”ì— ì´ë¥´ëŠ” End-to-End íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

## ğŸ“Œ 1. í”„ë¡œì íŠ¸ ê°œìš” (Overview)

ë³¸ í”„ë¡œì íŠ¸ëŠ” 'ì§ë°©' ì•±ì—ì„œ ë°œìƒí•˜ëŠ” ì‚¬ìš©ì í–‰ë™ ë¡œê·¸(e.g., ë§¤ë¬¼ ì¡°íšŒ, ì°œí•˜ê¸°, ì§€ì—­ ê²€ìƒ‰)ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì„¤ê³„í•˜ê³  êµ¬í˜„í•©ë‹ˆë‹¤.

ë°ì´í„° ì—”ì§€ë‹ˆì–´ì˜ ì‹¤ë¬´ì  ì—­í• ì„ ê²½í—˜í•˜ê¸° ìœ„í•´, **ë°°ì¹˜(Batch) íŒŒì´í”„ë¼ì¸**ì„ ìš°ì„ ì ìœ¼ë¡œ êµ¬ì¶•í•˜ì—¬ ì•ˆì •ì ì¸ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤(D.W) ë° ë°ì´í„° ë§ˆíŠ¸(D.M)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´í›„, **ì‹¤ì‹œê°„(Real-time) íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ í™•ì¥í•˜ì—¬ ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

* **í”„ë¡œì íŠ¸ ê¸°ê°„:** 2025.10.25 (í† ) ~ 2025.10.29 (ìˆ˜) (ì´ 5ì¼)
* **íŒ€ êµ¬ì„±:** 2ëª…
* **í•µì‹¬ ëª©í‘œ:**
    1.  ëŒ€ìš©ëŸ‰ ë¡œê·¸ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬ì¶•
    2.  (Optional) ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬ì¶•
    3.  D.W / D.M ì„¤ê³„ë¥¼ í†µí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    4.  ë°°ì¹˜/ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•œ ë°ì´í„° ì‹œê°í™”
    5.  Gitì„ í†µí•œ í˜‘ì—… ì›Œí¬í”Œë¡œìš° ê²½í—˜

---

## âœ¨ 2. ì£¼ìš” ê¸°ëŠ¥ ë° ëª©í‘œ (Key Features & Goals)

| êµ¬ë¶„ | ì£¼ìš” ê¸°ëŠ¥ (ëª©í‘œ) | ì„¤ëª… |
|---|---|---|
| ğŸ“¦ **ë°°ì¹˜ íŒŒì´í”„ë¼ì¸** | **D.W & D.M êµ¬ì¶•** | Kafkaë¡œ ìœ ì…ëœ ë¡œê·¸ë¥¼ S3 Data Lakeì— ì ì¬í•˜ê³ , Spark Batchë¡œ ì¼/ì‹œê°„ ë‹¨ìœ„ë¡œ ETL ì‘ì—…ì„ ìˆ˜í–‰í•˜ì—¬ D.Wì— ì ì¬í•©ë‹ˆë‹¤. ì´í›„ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­(e.g., ì§€ì—­ë³„ ì¸ê¸° ë§¤ë¬¼)ì— ë§ì¶˜ D.Mì„ êµ¬ì¶•í•©ë‹ˆë‹¤. |
| ğŸ“Š **ë°°ì¹˜ ëŒ€ì‹œë³´ë“œ** | **ì£¼ìš” ì§€í‘œ ì‹œê°í™”** | D.Mì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **BI íˆ´(Superset, Metabase ë“±)**ì„ ì—°ë™í•˜ì—¬, DAU/WAU, ê°€ì¥ ë§ì´ ì¡°íšŒëœ ì§€ì—­, ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½ ë“± í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. |
| âš¡ **(Optional)<br>ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸** | **ì‹¤ì‹œê°„ ì§‘ê³„** | Kafkaì˜ í† í”½ì„ Spark Streamingìœ¼ë¡œ ì§ì ‘ ì†Œë¹„(Consume)í•˜ì—¬, 'ìµœê·¼ 5ë¶„ê°„ ì°œì´ ê°€ì¥ ë§ì´ ëˆŒë¦° ë§¤ë¬¼' ë“± ì‹¤ì‹œê°„ì„± ì§€í‘œë¥¼ ì§‘ê³„í•˜ê³  ë³„ë„ DBì— ì €ì¥í•©ë‹ˆë‹¤. |
| ğŸ“ˆ **(Optional)<br>ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ** | **ì‹¤ì‹œê°„ í˜„í™© ëª¨ë‹ˆí„°ë§** | ì‹¤ì‹œê°„ ì§‘ê³„ DBì˜ ë°ì´í„°ë¥¼ **ì‹œê°í™” íˆ´(Grafana, Streamlit ë“±)**ê³¼ ì—°ë™í•˜ì—¬, í˜„ì¬ ì„œë¹„ìŠ¤ í˜„í™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ëŒ€ì‹œë³´ë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. |

---

## ğŸ§± 3. ì•„í‚¤í…ì²˜ (Architecture)

### A. ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ (Batch Pipeline) - (Main Priority)

`[Kafka] -> [AWS S3 (Data Lake)] -> [Spark Batch (ETL)] -> [Data Warehouse (D.W)] -> [Data Mart (D.M)] -> [BI Dashboard (Superset/Metabase)]`

### B. ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ (Real-time Pipeline) - (Optional)

`[Kafka] -> [Spark Streaming] -> [Real-time DB (Redis/MongoDB)] -> [Real-time Dashboard (Grafana/Streamlit)]`

---

## ğŸ› ï¸ 4. ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)

| êµ¬ì„± ìš”ì†Œ | ì‚¬ìš© ê¸°ìˆ  | ë¹„ê³  |
|---|---|---|
| **Data Ingestion** | Apache Kafka | ë¡œê·¸ ë°ì´í„° ìˆ˜ì§‘ |
| **Data Lake** | AWS S3 | ì›ë³¸ ë¡œê·¸(Raw data) ì ì¬ |
| **Data Processing** | Apache Spark (Batch, Streaming) | ETL ë° ì‹¤ì‹œê°„ ì§‘ê³„ |
| **Data Warehouse** | PostgreSQL / Amazon Redshift / BigQuery | ì •ì œëœ ë°ì´í„° ë° Fact/Dimension í…Œì´ë¸” ì ì¬ |
| **Real-time DB** | Redis / MongoDB | ì‹¤ì‹œê°„ ì§‘ê³„ ê²°ê³¼ ì €ì¥ (Optional) |
| **Orchestration** | Apache Airflow / Crontab | ë°°ì¹˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ (Optional) |
| **Dashboard (Batch)** | Apache Superset / Metabase | D.M ë°ì´í„° ì‹œê°í™” |
| **Dashboard (Real-time)** | Grafana / Streamlit | ì‹¤ì‹œê°„ ì§€í‘œ ì‹œê°í™” (Optional) |
| **Infra** | Docker, Docker-Compose | ë¡œì»¬ ê°œë°œ í™˜ê²½ êµ¬ì„± |
| **Version Control** | Git, GitHub | ì†ŒìŠ¤ ì½”ë“œ ê´€ë¦¬ ë° í˜‘ì—… |

---

## ğŸš€ 5. ì‹¤í–‰ ê°€ì´ë“œ (Quick Start)

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Docker ë° Docker Compose ì„¤ì¹˜
- ìµœì†Œ 8GB ë©”ëª¨ë¦¬ ê¶Œì¥
- ì‚¬ìš© í¬íŠ¸:
  - `8080`: Airflow Webserver
  - `8501`: Streamlit Dashboard
  - `5432`: PostgreSQL
  - `9092`: Kafka
  - `2181`: Zookeeper

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ê¶Œì¥)

í•œ ë²ˆì˜ ëª…ë ¹ìœ¼ë¡œ ë°°ì¹˜ + ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ëª¨ë‘ ì‹¤í–‰:

```bash
# 1. Docker Composeë¡œ ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘
docker-compose up -d

# 2. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose ps

# 3. ë¡œê·¸ í™•ì¸ (ê°ê° ë³„ë„ í„°ë¯¸ë„ì—ì„œ)
docker-compose logs -f spark-streaming  # ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¡œê·¸
docker-compose logs -f kafka-producer   # ë°ì´í„° ìƒì„± ë¡œê·¸
docker-compose logs -f streamlit        # ëŒ€ì‹œë³´ë“œ ë¡œê·¸
docker-compose logs -f airflow-scheduler # ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸
```

### ì„œë¹„ìŠ¤ ì ‘ì†

- **Airflow** (ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬): http://localhost:8080
  - Username: `admin`
  - Password: `admin`
  - DAG: `zigbang_daily_batch` í™œì„±í™”í•˜ì—¬ ë°°ì¹˜ ì‹¤í–‰

- **Streamlit Dashboard** (ë¶„ì„ ê²°ê³¼ ì¡°íšŒ): http://localhost:8501
  - 5ê°œ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€:
    1. ì§€ì—­ë³„ ê²€ìƒ‰ëŸ‰ ëŒ€ì‹œë³´ë“œ
    2. ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
    3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹œë³´ë“œ
    4. ì„¸ì…˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
    5. Funnel ë¶„ì„ ëŒ€ì‹œë³´ë“œ

### ì„œë¹„ìŠ¤ ê´€ë¦¬

```bash
# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¬ì‹œì‘
docker-compose restart spark-streaming
docker-compose restart kafka-producer

# ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ì§€
docker-compose down

# ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ì§€ ë° ë³¼ë¥¨ ì‚­ì œ (ë°ì´í„° ì´ˆê¸°í™”)
docker-compose down -v
```

### ë¡œì»¬ ê°œë°œ í™˜ê²½ (Docker ì—†ì´)

```bash
# 1. Python ê°€ìƒí™˜ê²½ ì„¤ì •
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate   # Windows

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install pyspark==3.4.4 kafka-python boto3 psycopg2-binary streamlit pandas plotly

# 3. ì¸í”„ë¼ë§Œ Dockerë¡œ ì‹œì‘
docker-compose up -d postgres kafka zookeeper

# 4. ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (íŠ¹ì • ë‚ ì§œ)
PYSPARK_PYTHON=.venv/bin/python PYSPARK_DRIVER_PYTHON=.venv/bin/python \
  .venv/bin/python src/batch/pipeline.py 2025-10-29

# 5. ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹¤í–‰
python src/streaming/kafka_producer.py  # í„°ë¯¸ë„ 1
.venv/bin/python src/streaming/streaming_job.py  # í„°ë¯¸ë„ 2

# 6. ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
cd src/streamlit_app && ../../.venv/bin/streamlit run Home.py
```

---

## ğŸ“ 6. ë””ë ‰í† ë¦¬ êµ¬ì¡° (Directory Structure)

```
log-pipeline/
â”œâ”€â”€ README.md                           # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
â”œâ”€â”€ CLAUDE.md                           # Claude Codeìš© í”„ë¡œì íŠ¸ ê°€ì´ë“œ
â”œâ”€â”€ docker-compose.yml                  # Docker Compose ì„¤ì • (ì „ì²´ ì¸í”„ë¼)
â”œâ”€â”€ Dockerfile                          # Airflow/Sparkìš© Dockerfile
â”œâ”€â”€ Dockerfile.streamlit                # Streamlit ëŒ€ì‹œë³´ë“œìš© Dockerfile
â”œâ”€â”€ .env                                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
â”œâ”€â”€ init-analytics-db.sql               # PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ init_tables.sql                     # í…Œì´ë¸” ìƒì„± ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ dags/                               # Airflow DAG íŒŒì¼ë“¤
â”‚   â””â”€â”€ daily_batch.py                  # ì¼ì¼ ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ DAG
â”‚
â”œâ”€â”€ src/                                # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ config/                         # ì„¤ì • íŒŒì¼
â”‚   â”‚   â””â”€â”€ config.py                   # ì „ì—­ ì„¤ì • (S3, PostgreSQL, Kafka, Spark)
â”‚   â”‚
â”‚   â”œâ”€â”€ batch/                          # ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ (Spark Batch)
â”‚   â”‚   â”œâ”€â”€ pipeline.py                 # ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â”‚   â”œâ”€â”€ extract.py                  # ë°ì´í„° ì¶”ì¶œ (S3 ë˜ëŠ” ë¡œì»¬)
â”‚   â”‚   â”œâ”€â”€ transform.py                # ë°ì´í„° ë³€í™˜ ë° ì§‘ê³„ (Spark)
â”‚   â”‚   â””â”€â”€ load.py                     # ë°ì´í„° ì ì¬ (PostgreSQL)
â”‚   â”‚
â”‚   â”œâ”€â”€ streaming/                      # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py           # Kafka ë¡œê·¸ ìƒì„±ê¸° (500 logs/sec)
â”‚   â”‚   â”œâ”€â”€ kafka_to_s3_consumer.py     # Kafka â†’ S3/ë¡œì»¬ Consumer
â”‚   â”‚   â””â”€â”€ streaming_job.py            # Spark Structured Streaming ì‘ì—…
â”‚   â”‚
â”‚   â”œâ”€â”€ streamlit_app/                  # Streamlit ëŒ€ì‹œë³´ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”‚   â”œâ”€â”€ Home.py                     # ëŒ€ì‹œë³´ë“œ í™ˆ í˜ì´ì§€
â”‚   â”‚   â”œâ”€â”€ utils.py                    # ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”‚   â””â”€â”€ pages/                      # ëŒ€ì‹œë³´ë“œ í˜ì´ì§€ë“¤
â”‚   â”‚       â”œâ”€â”€ 1_ì§€ì—­ë³„ ê²€ìƒ‰ëŸ‰ ëŒ€ì‹œë³´ë“œ.py
â”‚   â”‚       â”œâ”€â”€ 2_ì‹œê°„ëŒ€ë³„ í™œë™ ë¶„ì„ ëŒ€ì‹œë³´ë“œ.py
â”‚   â”‚       â”œâ”€â”€ 3_ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹œë³´ë“œ.py
â”‚   â”‚       â”œâ”€â”€ 4_ì„¸ì…˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ.py
â”‚   â”‚       â””â”€â”€ 5_Funnel ë¶„ì„ ëŒ€ì‹œë³´ë“œ.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                          # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚       â””â”€â”€ change_log_dates.py         # ë¡œê·¸ ë‚ ì§œ ë³€ê²½ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ data/                               # ë¡œì»¬ ë°ì´í„° ì €ì¥ì†Œ (Data Lake)
â”‚   â””â”€â”€ date=YYYY-MM-DD/                # ë‚ ì§œë³„ íŒŒí‹°ì…˜
â”‚       â””â”€â”€ *.csv.gz                    # ì••ì¶•ëœ ë¡œê·¸ íŒŒì¼
â”‚
â”œâ”€â”€ results/                            # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ (ì¤‘ê°„ ì‚°ì¶œë¬¼)
â”‚   â”œâ”€â”€ silver/                         # ì •ì œëœ ë°ì´í„°
â”‚   â””â”€â”€ gold/                           # ì§‘ê³„ëœ ë°ì´í„°
â”‚
â”œâ”€â”€ test_postgres.py                    # PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_spark_postgres.py              # Spark-PostgreSQL í†µí•© í…ŒìŠ¤íŠ¸
â”œâ”€â”€ generate_synthetic_data.py          # í•©ì„± ë°ì´í„° ìƒì„±ê¸°
â””â”€â”€ generate_streaming_data.py          # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ìƒì„±ê¸°
```
